{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"..\\Extracted_files\\HHV1_PERV1_merged.dta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming value labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unique values in sector are ['1' '2']\n"
     ]
    }
   ],
   "source": [
    "#Renaming sector values\n",
    "print(f\" Unique values in sector are {df[\"pvar5\"].unique()}\")\n",
    "df[\"pvar5\"] = df[\"pvar5\"].replace({\"1\": \"rural\", \"2\": \"urban\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unique values in gender are ['1' '2' '3']\n"
     ]
    }
   ],
   "source": [
    "#Renaming gender\n",
    "print(f\" Unique values in gender are {df[\"pvar19\"].unique()}\")\n",
    "df[\"pvar19\"] = df[\"pvar19\"].replace({\"1\": \"male\", \"2\": \"female\", \"3\": \"transgender\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unique values in states are ['02' '21' '20' '01' '24' '03' '23' '33' '36' '08' '09' '19' '27' '16'\n",
      " '10' '22' '28' '32' '18' '14' '06' '15' '29' '11' '05' '37' '30' '34'\n",
      " '12' '17' '35' '13' '25' '07' '31' '04']\n"
     ]
    }
   ],
   "source": [
    "#Renaming states\n",
    "print(f\" Unique values in states are {df[\"pvar6\"].unique()}\")\n",
    "\n",
    "state_code = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\"]\n",
    "\n",
    "state_name = [\"Jammu & Kashmir\",\t\"Himachal Pradesh\",\t\"Punjab\",\t\"Chandigarh\",\t\"Uttarakhand\",\t\"Haryana\",\t\"Delhi\",\t\"Rajasthan\",\t\"Uttar Pradesh\",\t\"Bihar\",\t\"Sikkim\",\t\"Arunachal Pradesh\",\t\"Nagaland\",\t\"Manipur\",\t\"Mizoram\",\t\"Tripura\",\t\"Meghalaya\",\t\"Assam\",\t\"West Bengal\",\t\"Jharkhand\",\t\"Odisha\",\t\"Chhattisgarh\",\t\"Madhya Pradesh\",\t\"Gujarat\",\t\"D & N. Haveli & Daman & Diu\",\t\"Maharashtra\",\t\"Andhra Pradesh\",\t\"Karnataka\",\t\"Goa\",\t\"Lakshadweep\",\t\"Kerala\",\t\"Tamilnadu\",\t\"Puduchery\",\t\"Andaman & N. Island\",\t\"Telangana\",\t\"Ladakh\"]\n",
    "\n",
    "state_dict = dict(zip(state_code,state_name))\n",
    "\n",
    "df[\"pvar6\"] = df[\"pvar6\"].replace(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating usual status code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"pvar32\", \"pvar43\"]] = df[[\"pvar32\", \"pvar43\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tarun\\AppData\\Local\\Temp\\ipykernel_34368\\3086264331.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['usual_status_code'] = df.apply(lambda row: row[\"pvar43\"] if ((row[\"pvar32\"]>=81) & pd.notna(row[\"pvar43\"])) else row[\"pvar32\"], axis=1)\n"
     ]
    }
   ],
   "source": [
    "df['usual_status_code'] = df.apply(lambda row: row[\"pvar43\"] if ((row[\"pvar32\"]>=81) & pd.notna(row[\"pvar43\"])) else row[\"pvar32\"], axis=1)\n",
    "#df['usual_status_code'] = df['usual_status_code'].astype(str) #Won't allow exporting objects, so converting to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhvar1</th>\n",
       "      <th>hhvar2</th>\n",
       "      <th>hhvar3</th>\n",
       "      <th>hhvar4</th>\n",
       "      <th>hhvar5</th>\n",
       "      <th>hhvar6</th>\n",
       "      <th>hhvar7</th>\n",
       "      <th>hhvar8</th>\n",
       "      <th>hhvar9</th>\n",
       "      <th>hhvar10</th>\n",
       "      <th>...</th>\n",
       "      <th>pvar134</th>\n",
       "      <th>pvar135</th>\n",
       "      <th>pvar136</th>\n",
       "      <th>pvar137</th>\n",
       "      <th>pvar138</th>\n",
       "      <th>pvar139</th>\n",
       "      <th>perid</th>\n",
       "      <th>_merge</th>\n",
       "      <th>weights</th>\n",
       "      <th>usual_status_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FVH7</td>\n",
       "      <td>104</td>\n",
       "      <td>Q1</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>021</td>\n",
       "      <td>01</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>246798</td>\n",
       "      <td>4</td>\n",
       "      <td>Q1V1110002110101</td>\n",
       "      <td>both</td>\n",
       "      <td>308</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FVH7</td>\n",
       "      <td>104</td>\n",
       "      <td>Q1</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>021</td>\n",
       "      <td>01</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>246798</td>\n",
       "      <td>4</td>\n",
       "      <td>Q1V1110002110102</td>\n",
       "      <td>both</td>\n",
       "      <td>308</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FVH7</td>\n",
       "      <td>104</td>\n",
       "      <td>Q1</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>021</td>\n",
       "      <td>01</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6500</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>246798</td>\n",
       "      <td>4</td>\n",
       "      <td>Q1V1110002110103</td>\n",
       "      <td>both</td>\n",
       "      <td>308</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FVH7</td>\n",
       "      <td>104</td>\n",
       "      <td>Q1</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>021</td>\n",
       "      <td>01</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>246798</td>\n",
       "      <td>4</td>\n",
       "      <td>Q1V1110002110104</td>\n",
       "      <td>both</td>\n",
       "      <td>308</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FVH7</td>\n",
       "      <td>104</td>\n",
       "      <td>Q1</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>04</td>\n",
       "      <td>021</td>\n",
       "      <td>01</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>246798</td>\n",
       "      <td>4</td>\n",
       "      <td>Q1V1110002110105</td>\n",
       "      <td>both</td>\n",
       "      <td>308</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hhvar1 hhvar2 hhvar3 hhvar4 hhvar5 hhvar6 hhvar7 hhvar8 hhvar9 hhvar10  ...  \\\n",
       "0   FVH7    104     Q1     V1      1     02     04    021     01      14  ...   \n",
       "1   FVH7    104     Q1     V1      1     02     04    021     01      14  ...   \n",
       "2   FVH7    104     Q1     V1      1     02     04    021     01      14  ...   \n",
       "3   FVH7    104     Q1     V1      1     02     04    021     01      14  ...   \n",
       "4   FVH7    104     Q1     V1      1     02     04    021     01      14  ...   \n",
       "\n",
       "  pvar134 pvar135 pvar136 pvar137 pvar138 pvar139             perid _merge  \\\n",
       "0       0       0       2       4  246798       4  Q1V1110002110101   both   \n",
       "1       0       0       2       4  246798       4  Q1V1110002110102   both   \n",
       "2       0    6500       2       4  246798       4  Q1V1110002110103   both   \n",
       "3       0       0       2       4  246798       4  Q1V1110002110104   both   \n",
       "4       0       0       2       4  246798       4  Q1V1110002110105   both   \n",
       "\n",
       "  weights usual_status_code  \n",
       "0     308              94.0  \n",
       "1     308              93.0  \n",
       "2     308              11.0  \n",
       "3     308              21.0  \n",
       "4     308              91.0  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_stata(r\"..\\Extracted_files\\HHV1_PERV1_merged.dta\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
